import gradio as gr
import os
import requests
from dotenv import load_dotenv
from prompts import prompt_templates

# è®€å–.env
load_dotenv()

# LLM è¨­å®š
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL")
LLM_MODEL = os.getenv("LLM_MODEL")

# STT è¨­å®š
STT_API_KEY = os.getenv("STT_API_KEY")
STT_BASE_URL = os.getenv("STT_BASE_URL")
STT_MODEL = os.getenv("STT_MODEL")

# å ´æ™¯é¸é …
SCENARIOS = list(prompt_templates.keys())

# èªè¨€é¸é …
LANGUAGES = ["ç¹é«”ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡"]


def transcribe_audio(audio_file):
    if audio_file is None:
        return ""

    headers = {
        "Authorization": f"Bearer {STT_API_KEY}"
    }
    files = {
        'file': (audio_file.name, audio_file, 'audio/mpeg')
    }
    data = {
        "model": STT_MODEL
    }
    response = requests.post(f"{STT_BASE_URL}/transcriptions", headers=headers, files=files, data=data)

    if response.status_code == 200:
        return response.json()['text']
    else:
        return "(èªéŸ³è½‰æ–‡å­—å¤±æ•—)"


def call_llm(prompt):
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": LLM_MODEL,
        "messages": [{"role": "user", "content": prompt}]
    }
    response = requests.post(f"{LLM_BASE_URL}/chat/completions", headers=headers, json=payload)

    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        return f"(LLMéŒ¯èª¤: {response.text})"


def generate_prompt(scene, language, content):
    template = prompt_templates.get(scene)
    lang_phrase = {
        "ç¹é«”ä¸­æ–‡": "ç¹é«”ä¸­æ–‡",
        "è‹±æ–‡": "English",
        "æ—¥æ–‡": "æ—¥æœ¬èª"
    }.get(language, "ç¹é«”ä¸­æ–‡")

    if template:
        return template.format(language=lang_phrase, content=content)
    else:
        return f"ä»¥ä¸‹æ˜¯æè¿°å…§å®¹ï¼š\n{content}"


def process(scene, language, text_input, audio_input):
    final_text = text_input

    if not final_text and audio_input is not None:
        final_text = transcribe_audio(audio_input)

    if not final_text:
        return "è«‹è¼¸å…¥æ–‡å­—æˆ–ä¸Šå‚³èªéŸ³ã€‚"

    prompt = generate_prompt(scene, language, final_text)
    result = call_llm(prompt)
    return result


with gr.Blocks() as demo:
    gr.Markdown("# ğŸ©º é†«ç™‚è¨˜éŒ„æ ¼å¼ç”¢ç”Ÿå™¨")

    with gr.Row():
        scene = gr.Dropdown(choices=SCENARIOS, label="é¸æ“‡å ´æ™¯")
        language = gr.Dropdown(choices=LANGUAGES, label="é¸æ“‡èªè¨€")

    text_input = gr.Textbox(label="è¼¸å…¥ç—…äººç‹€æ³æ–‡å­—", placeholder="è«‹è¼¸å…¥æè¿°...", lines=4)
    audio_input = gr.Audio(label="æˆ–ä¸Šå‚³èªéŸ³æª”æ¡ˆ", type="file")

    submit_btn = gr.Button("ç”¢ç”Ÿè¨˜éŒ„")

    result = gr.Textbox(label="çµæœï¼ˆå¯è¤‡è£½ï¼‰", lines=20)
    copy_btn = gr.Button("è¤‡è£½çµæœ")

    submit_btn.click(
        process,
        inputs=[scene, language, text_input, audio_input],
        outputs=[result]
    )

    copy_btn.click(lambda x: x, inputs=[result], outputs=[result], api_name="copy")


if __name__ == "__main__":
    demo.launch()